{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c13e549",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ST-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9372fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.nn import init\n",
    "#import transforms.ISTD_transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a30c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inconv(nn.Module): #Extracting feature with kernel (4x4), stride = 2, padding = 1\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class lrl_conv_bn(nn.Module): #Extracting feature with kernel (4x4), stride = 2, padding = 1 but leaky_relu is before and batchnorm2d is after\n",
    "    '''Leaky ReLU -> Conv -> BN'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(lrl_conv_bn, self).__init__()\n",
    "        self.conv_bn = nn.Sequential(\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_bn(x)\n",
    "        return x\n",
    "\n",
    "class lrl_conv_bn_triple(nn.Module): #Triple layer\n",
    "    '''Leaky ReLU -> Conv -> BN'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(lrl_conv_bn_triple, self).__init__()\n",
    "        self.conv_bn = nn.Sequential(\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_bn(x)\n",
    "        return x\n",
    "\n",
    "class lrl_conv(nn.Module): #Without batch normalization\n",
    "    '''Leaky ReLU -> Conv'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(lrl_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class rl_convT_bn(nn.Module): #Relu but not leaky relu\n",
    "    '''ReLU -> ConvT -> BN'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(rl_convT_bn, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class rl_convT_bn_triple(nn.Module): #Triple relu\n",
    "    '''ReLU -> ConvT -> BN'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(rl_convT_bn_triple, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(out_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(out_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class rl_convT(nn.Module): #Relu without batch\n",
    "    '''ReLU -> ConvT'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(rl_convT, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffbd8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(generator, self).__init__()\n",
    "        self.inc = inconv(in_ch, 64)\n",
    "        self.conv_1 = lrl_conv_bn(64, 128)\n",
    "        self.conv_2 = lrl_conv_bn(128, 256)\n",
    "        self.conv_3 = lrl_conv_bn(256, 512)\n",
    "        self.conv_4 = lrl_conv_bn_triple(512, 512)\n",
    "        self.conv_5 = lrl_conv(512, 512)\n",
    "        self.conv_T6 = rl_convT_bn(512, 512)\n",
    "        self.conv_T7 = rl_convT_bn_triple(1024,512)\n",
    "        self.conv_T8 = rl_convT_bn(1024, 256)\n",
    "        self.conv_T9 = rl_convT_bn(512, 128)\n",
    "        self.conv_T10 = rl_convT_bn(256, 64)\n",
    "        self.conv_T11 = rl_convT(128, out_ch)\n",
    "\n",
    "    def forward(self, input):\n",
    "        cv0 = self.inc(input)\n",
    "        cv1 = self.conv_1(cv0)\n",
    "        cv2 = self.conv_2(cv1)\n",
    "        cv3 = self.conv_3(cv2)\n",
    "        cv4 = self.conv_4(cv3)\n",
    "        cv5 = self.conv_5(cv4)\n",
    "        cvT6 = self.conv_T6(cv5)\n",
    "        input7 = torch.cat([cvT6, cv4], dim=1)\n",
    "        cvT7 = self.conv_T7(input7)\n",
    "        input8 = torch.cat([cvT7, cv3], dim=1)\n",
    "        cvT8 = self.conv_T8(input8)\n",
    "        input9 = torch.cat([cvT8, cv2], dim=1)\n",
    "        cvT9 = self.conv_T9(input9)\n",
    "        input10 = torch.cat([cvT9, cv1], dim=1)\n",
    "        cvT10 = self.conv_T10(input10)\n",
    "        input11 = torch.cat([cvT10, cv0], dim=1)\n",
    "        cvT11 = self.conv_T11(input11)\n",
    "        out = torch.tanh(cvT11)\n",
    "        return out\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.inc = inconv(in_ch, 64)\n",
    "        self.conv_1 = lrl_conv_bn(64, 128)\n",
    "        self.conv_2 = lrl_conv_bn(128, 256)\n",
    "        self.conv_3 = lrl_conv_bn(256, 512)\n",
    "        self.conv_4 = lrl_conv(512, out_ch)\n",
    "\n",
    "    def forward(self, input):\n",
    "        cv0 = self.inc(input)\n",
    "        cv1 = self.conv_1(cv0)\n",
    "        cv2 = self.conv_2(cv1)\n",
    "        cv3 = self.conv_3(cv2)\n",
    "        cv4 = self.conv_4(cv3)\n",
    "        out = torch.sigmoid(cv4)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c39df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_trained = generator(3, 1)\n",
    "G2_trained = generator(4, 3)\n",
    "D1_trained = discriminator(4, 1)\n",
    "D2_trained = discriminator(7, 1)\n",
    "\n",
    "root_path = os.getcwd()\n",
    "model_path = os.path.dirname(root_path) + \"\\\\checkpoints_STGAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0726367e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator(\n",
       "  (inc): inconv(\n",
       "    (conv): Conv2d(7, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (conv_1): lrl_conv_bn(\n",
       "    (conv_bn): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_2): lrl_conv_bn(\n",
       "    (conv_bn): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_3): lrl_conv_bn(\n",
       "    (conv_bn): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_4): lrl_conv(\n",
       "    (conv): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (1): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epoch = 49\n",
    "G1_trained.load_state_dict(torch.load(model_path+\"\\\\G1_\" + str(num_epoch) + \".pth\"))\n",
    "G1_trained.eval()\n",
    "G2_trained.load_state_dict(torch.load(model_path+\"\\\\G2_\" + str(num_epoch) + \".pth\"))\n",
    "G2_trained.eval()\n",
    "D1_trained.load_state_dict(torch.load(model_path+\"\\\\D1_\" + str(num_epoch) + \".pth\"))\n",
    "D1_trained.eval()\n",
    "D2_trained.load_state_dict(torch.load(model_path+\"\\\\D2_\" + str(num_epoch) + \".pth\"))\n",
    "D2_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1f4aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator(\n",
       "  (inc): inconv(\n",
       "    (conv): Conv2d(7, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (conv_1): lrl_conv_bn(\n",
       "    (conv_bn): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_2): lrl_conv_bn(\n",
       "    (conv_bn): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_3): lrl_conv_bn(\n",
       "    (conv_bn): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_4): lrl_conv(\n",
       "    (conv): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (1): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send to GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "cuda_tensor = torch.cuda.FloatTensor if device == torch.device('cuda:0') else torch.FloatTensor\n",
    "G1_trained.to(device)\n",
    "G2_trained.to(device)\n",
    "D1_trained.to(device)\n",
    "D2_trained.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5476c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SP-M NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ccceb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from options.train_options import TrainOptions\n",
    "from options.test_options import TestOptions\n",
    "from data import CustomDatasetDataLoader\n",
    "from models import create_model\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import util.util as util\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "990390fd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 2                             \n",
      "          checkpoints_dir: C:/Users/m1101/Downloads/Shadow_Removal/SID/_Git_SID/checkpoints_PAMI/\n",
      "                 dataroot: C:/Users/m1101/Downloads/Shadow_Removal/SID/_Git_SID/data_processing/dataset/NTUST_TU/train/\n",
      "             dataset_mode: shadowparam                   \n",
      "                    epoch: latest                        \n",
      "                 fineSize: 256                           \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: xavier                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "               lambda_GAN: 0.0                           \n",
      "                lambda_L1: 100                           \n",
      "            lambda_smooth: 0.0                           \n",
      "                 loadSize: 256                           \n",
      "                       lr: 0.0002                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: SID                           \n",
      "                     name: SID_GRESNEXT_shadowparam      \n",
      "                      ndf: 64                            \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: True                          \n",
      "                 no_lsgan: True                          \n",
      "                     norm: batch                         \n",
      "              num_threads: 2                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train_                        \n",
      "                pool_size: 0                             \n",
      "           resize_or_crop: resize_and_crop               \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "----------------- End -------------------\n"
     ]
    }
   ],
   "source": [
    "opt = TestOptions().parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71920168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [ShadowParamDataset] was created\n"
     ]
    }
   ],
   "source": [
    "data_loader = CustomDatasetDataLoader(opt) #createDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "dataset_size = len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c1e17b3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with xavier\n",
      "model [Shadow Image Decomposition model ICCV19] was created\n",
      "<bound method SIDModel.name of <models.model_SID.SIDModel object at 0x00000294FBB92430>>\n",
      "LOADING <bound method SIDModel.name of <models.model_SID.SIDModel object at 0x00000294FBB92430>>\n",
      "loading the model from C:/Users/m1101/Downloads/Shadow_Removal/SID/_Git_SID/checkpoints_PAMI/SID_GRESNEXT_shadowparam\\latest_net_G.pth\n",
      "loading the model from C:/Users/m1101/Downloads/Shadow_Removal/SID/_Git_SID/checkpoints_PAMI/SID_GRESNEXT_shadowparam\\latest_net_M.pth\n",
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): ResNet(\n",
      "    (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (6): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (7): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (8): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (9): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (10): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (11): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (12): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (13): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (14): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (15): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (16): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (17): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (18): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (19): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (20): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (21): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (22): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "[Network G] Total number of parameters : 86.758 M\n",
      "DataParallel(\n",
      "  (module): UnetModel(\n",
      "    (model): UnetSkipConnectionBlock(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(7, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): UnetSkipConnectionBlock(\n",
      "          (model): Sequential(\n",
      "            (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "            (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): UnetSkipConnectionBlock(\n",
      "              (model): Sequential(\n",
      "                (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (3): UnetSkipConnectionBlock(\n",
      "                  (model): Sequential(\n",
      "                    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                    (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (3): UnetSkipConnectionBlock(\n",
      "                      (model): Sequential(\n",
      "                        (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                        (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (3): UnetSkipConnectionBlock(\n",
      "                          (model): Sequential(\n",
      "                            (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                            (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (3): UnetSkipConnectionBlock(\n",
      "                              (model): Sequential(\n",
      "                                (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (3): UnetSkipConnectionBlock(\n",
      "                                  (model): Sequential(\n",
      "                                    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                    (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (2): ReLU(inplace=True)\n",
      "                                    (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                  )\n",
      "                                )\n",
      "                                (4): ReLU(inplace=True)\n",
      "                                (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (7): Dropout(p=0.5, inplace=False)\n",
      "                              )\n",
      "                            )\n",
      "                            (4): ReLU(inplace=True)\n",
      "                            (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (7): Dropout(p=0.5, inplace=False)\n",
      "                          )\n",
      "                        )\n",
      "                        (4): ReLU(inplace=True)\n",
      "                        (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (7): Dropout(p=0.5, inplace=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (4): ReLU(inplace=True)\n",
      "                    (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "                (4): ReLU(inplace=True)\n",
      "                (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (4): ReLU(inplace=True)\n",
      "            (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "        (4): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network M] Total number of parameters : 54.418 M\n",
      "-----------------------------------------------\n",
      "loading the model from C:/Users/m1101/Downloads/Shadow_Removal/SID/_Git_SID/checkpoints_PAMI/SID_GRESNEXT_shadowparam\\50_net_G.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the model from C:/Users/m1101/Downloads/Shadow_Removal/SID/_Git_SID/checkpoints_PAMI/SID_GRESNEXT_shadowparam\\50_net_M.pth\n"
     ]
    }
   ],
   "source": [
    "test_model = create_model(opt)\n",
    "test_model.setup(opt)\n",
    "test_model.load_networks(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc26f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run(input_img, shadow_mask):\n",
    "#     inputG = torch.cat([input_img,shadow_mask],1)\n",
    "#     shadow_mask = (shadow_mask>0.9)*2-1\n",
    "#     shadow_mask_3d= (shadow_mask>0).expand(input_img.shape)   \n",
    "\n",
    "#     inputG = F.interpolate(inputG,size=(256,256))\n",
    "#     shadow_param_pred = test_model.netG(inputG)\n",
    "#     w = input_img.shape[2]\n",
    "#     h = input_img.shape[3]\n",
    "#     n = input_img.shape[0]\n",
    "#     m = input_img.shape[1]\n",
    "#     shadow_param_pred = shadow_param_pred.view([n,6,-1])\n",
    "#     shadow_param_pred = torch.mean(shadow_param_pred,dim=2)\n",
    "#     shadow_param_pred[:,[1,3,5]] = (shadow_param_pred[:,[1,3,5]]*2)+3 \n",
    "\n",
    "#     lit = input_img.clone()/2+0.5\n",
    "#     add = shadow_param_pred[:,[0,2,4]]\n",
    "#     mul = shadow_param_pred[:,[1,3,5]]\n",
    "#     #mul = (mul +2) * 5/3          \n",
    "#     n = shadow_param_pred.shape[0]\n",
    "#     add = add.view(n,3,1,1).expand((n,3,w,h))\n",
    "#     mul = mul.view(n,3,1,1).expand((n,3,w,h))\n",
    "#     lit = lit*mul + add\n",
    "#     out = (input_img/2+0.5)*~(shadow_mask_3d) + lit*shadow_mask_3d\n",
    "#     out = out*2-1\n",
    "\n",
    "#     inputM = torch.cat([input_img,lit,shadow_mask],1)\n",
    "#     alpha_pred = test_model.netM(inputM)\n",
    "#     alpha_pred = (alpha_pred +1) /2        \n",
    "#     #alpha_pred_3d=  alpha_pred.repeat(1,3,1,1)\n",
    "\n",
    "#     final = (input_img/2+0.5)*(1-alpha_pred) + lit*alpha_pred\n",
    "#     final = final*2-1\n",
    "\n",
    "#     RES = dict()\n",
    "#     RES['final']= util.tensor2im(final,scale =0)\n",
    "#     RES['phase1'] = util.tensor2im(out,scale =0)\n",
    "#     RES['param']= shadow_param_pred.detach().cpu() \n",
    "#     RES['matte'] = util.tensor2im(alpha_pred.detach().cpu()/2,scale =0)\n",
    "    \n",
    "#     return RES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f179a4f",
   "metadata": {},
   "source": [
    "# ASSESS AND SAVE IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "828af052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def progressbar(it, prefix=\"\", size=60, out=sys.stdout): # Python3.3+\n",
    "    count = len(it)\n",
    "    def show(j, batch_size):\n",
    "        n = batch_size*j\n",
    "        x = int(size*n/count)\n",
    "        print(\"{}[{}{}] {}/{}\".format(prefix, \"#\"*x, \".\"*(size-x), n, count), \n",
    "                end='\\r', file=out, flush=True)\n",
    "    show(0, 1)\n",
    "    for i, item in enumerate(it):\n",
    "        yield item\n",
    "        batch_size = len(list(item.values())[0])\n",
    "        show(i+1, batch_size)\n",
    "    print(\"\\n\", flush=True, file=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad8bd1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# def calculate_psnr(img1, img2):\n",
    "#     img1 = img1.astype(np.float64)\n",
    "#     img2 = img2.astype(np.float64)\n",
    "#     mse = np.mean((img1 - img2)**2)\n",
    "#     if mse == 0:\n",
    "#         return float('inf')\n",
    "#     return 20 * math.log10(255.0 / math.sqrt(mse))\n",
    "\n",
    "# def ssim(img1, img2):\n",
    "#     C1 = (0.01 * 255)**2\n",
    "#     C2 = (0.03 * 255)**2\n",
    "\n",
    "#     img1 = img1.astype(np.float64)\n",
    "#     img2 = img2.astype(np.float64)\n",
    "#     kernel = cv2.getGaussianKernel(11, 1.5)\n",
    "#     window = np.outer(kernel, kernel.transpose())\n",
    "\n",
    "#     mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
    "#     mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
    "#     mu1_sq = mu1**2\n",
    "#     mu2_sq = mu2**2\n",
    "#     mu1_mu2 = mu1 * mu2\n",
    "#     sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
    "#     sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
    "#     sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
    "\n",
    "#     ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n",
    "#                                                             (sigma1_sq + sigma2_sq + C2))\n",
    "#     return ssim_map.mean()\n",
    "\n",
    "\n",
    "# def calculate_ssim(img1, img2):\n",
    "#     '''calculate SSIM\n",
    "#     the same outputs as MATLAB's\n",
    "#     img1, img2: [0, 255]\n",
    "#     '''\n",
    "#     if not img1.shape == img2.shape:\n",
    "#         raise ValueError('Input images must have the same dimensions.')\n",
    "#     if img1.ndim == 2:\n",
    "#         return ssim(img1, img2)\n",
    "#     elif img1.ndim == 3:\n",
    "#         if img1.shape[2] == 3:\n",
    "#             ssims = []\n",
    "#             for i in range(3):\n",
    "#                 ssims.append(ssim(img1, img2))\n",
    "#             return np.array(ssims).mean()\n",
    "#         elif img1.shape[2] == 1:\n",
    "#             return ssim(np.squeeze(img1), np.squeeze(img2))\n",
    "#     else:\n",
    "#         raise ValueError('Wrong input image dimensions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07937bf",
   "metadata": {},
   "source": [
    "## Assessing and Saving Images at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72bd9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(os.getcwd() + f\"\\\\result_set\\\\original\").mkdir(parents=True, exist_ok=True)\n",
    "Path(os.getcwd() + f\"\\\\result_set\\\\stgan\").mkdir(parents=True, exist_ok=True)\n",
    "Path(os.getcwd() + f\"\\\\result_set\\\\sid\").mkdir(parents=True, exist_ok=True)\n",
    "Path(os.getcwd() + f\"\\\\result_set\\\\groudtruth\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57504e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# my_psnr = 0\n",
    "# my_psnr_A = 0\n",
    "# my_psnr_B = 0\n",
    "\n",
    "# my_ssim = 0\n",
    "# my_ssim_A = 0\n",
    "# my_ssim_B = 0\n",
    "\n",
    "# epoch_index = -1\n",
    "# for data in progressbar(dataset):\n",
    "#     list_A = Variable(data['A'].type(cuda_tensor), 0)\n",
    "#     list_C = Variable(data['C'].type(cuda_tensor), 0)\n",
    "#     list_imname = data['imname']\n",
    "    \n",
    "#     list_A = torch.reshape(list_A,(-1,3,256,256))\n",
    "#     list_C = torch.reshape(list_C,(-1,3,256,256))\n",
    "#     input_img = list_A \n",
    "#     shadow_mask = G1_trained(input_img) \n",
    "#     img_fake_B = (shadow_mask[0] + 1.0)/2.0\n",
    "#     blur_ = cv2.GaussianBlur(img_fake_B[0].cpu().detach().numpy(), (0,0), 4.0, 4.0)\n",
    "#     blur = torch.from_numpy(blur_).type(cuda_tensor)[None, None, :, :]\n",
    "#     blur = (blur - 0.5)*2.0\n",
    "    \n",
    "#     fake_C_ST_GAN = G2_trained(torch.cat((input_img, shadow_mask), 1))\n",
    "#     RES = run(input_img, blur)\n",
    "    \n",
    "#     epoch_index += 1\n",
    "#     for i in range(len(list_A)):\n",
    "#         img_real_A = list_A[i].permute(1, 2, 0)\n",
    "#         img_real_C = list_C[i].permute(1, 2, 0)\n",
    "#         img_fake_C = fake_C_ST_GAN[i].data.permute(1, 2, 0)\n",
    "\n",
    "#         #Scale to 255\n",
    "#         img_real_A = ((img_real_A + 1.0)*255.0/2.0).cpu().numpy().astype(np.uint8)\n",
    "#         img_real_C = ((img_real_C + 1.0)*255.0/2.0).cpu().numpy().astype(np.uint8) \n",
    "#         img_fake_C = ((img_fake_C + 1.0)*255.0/2.0).cpu().numpy().astype(np.uint8) \n",
    "#         img_fake_C_SID = RES['final']\n",
    "        \n",
    "#         data_name = os.getcwd() + f\"\\\\result_set\\\\original\\\\{list_imname[i]}\"\n",
    "#         Image.fromarray(img_real_A).convert('RGB').resize((224, 224)).save(data_name)\n",
    "        \n",
    "#         data_name = os.getcwd() + f\"\\\\result_set\\\\stgan\\\\{list_imname[i]}\"              \n",
    "#         Image.fromarray(img_fake_C).convert('RGB').resize((224, 224)).save(data_name)\n",
    "        \n",
    "#         data_name = os.getcwd() + f\"\\\\result_set\\\\sid\\\\{list_imname[i]}\"              \n",
    "#         Image.fromarray(img_fake_C_SID).convert('RGB').resize((224, 224)).save(data_name)\n",
    "        \n",
    "#         data_name = os.getcwd() + f\"\\\\result_set\\\\groudtruth\\\\{list_imname[i]}\"              \n",
    "#         Image.fromarray(img_real_C).convert('RGB').resize((224, 224)).save(data_name)\n",
    "\n",
    "#         my_psnr += calculate_psnr(img_real_C, img_real_A)\n",
    "#         my_ssim += calculate_ssim(img_real_C, img_real_A)\n",
    "\n",
    "#         my_psnr_A += calculate_psnr(img_real_C, img_fake_C)\n",
    "#         my_ssim_A += calculate_ssim(img_real_C, img_fake_C)\n",
    "        \n",
    "#         my_psnr_B += calculate_psnr(img_real_C, img_fake_C_SID)\n",
    "#         my_ssim_B += calculate_ssim(img_real_C, img_fake_C_SID)\n",
    "        \n",
    "# #         if epoch_index == 20:\n",
    "# #             break\n",
    "    \n",
    "# length = len(list_A)*len(dataset)\n",
    "# print(\"Amount of data: \", length)\n",
    "# print(\"PSNR 0: \", my_psnr/length, \"SSIM 0: \", my_ssim/length)\n",
    "# print(\"PSNR A: \", my_psnr_A/length, \"SSIM A: \", my_ssim_A/length)\n",
    "# print(\"PSNR B: \", my_psnr_B/length, \"SSIM B: \", my_ssim_B/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3632494b-7d67-4e5a-9d61-19c79d488a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[............................................................] 12/1600\r"
     ]
    }
   ],
   "source": [
    "from models.loss_function import calculate_ssim, calculate_psnr\n",
    "\n",
    "my_psnr = 0\n",
    "my_psnr_A = 0\n",
    "my_psnr_B = 0\n",
    "\n",
    "my_ssim = 0\n",
    "my_ssim_A = 0\n",
    "my_ssim_B = 0\n",
    "\n",
    "epoch_index = -1\n",
    "for data in progressbar(dataset):\n",
    "    list_A = Variable(data['A'].type(cuda_tensor), 0)\n",
    "    list_C = Variable(data['C'].type(cuda_tensor), 0)\n",
    "    list_imname = data['imname']\n",
    "    \n",
    "    list_A = torch.reshape(list_A,(-1,3,256,256))\n",
    "    list_C = torch.reshape(list_C,(-1,3,256,256))\n",
    "    input_img = list_A \n",
    "    shadow_mask = G1_trained(input_img) \n",
    "    \n",
    "    # blur shadow image\n",
    "    img_fake_B = (shadow_mask + 1.0)/2.0\n",
    "#     for i_blur in range(len(img_fake_B)):\n",
    "#         blur_ = cv2.GaussianBlur(img_fake_B[i_blur].cpu().detach().numpy(), (0,0), 4.0, 4.0)\n",
    "#         img_fake_B[i_blur] = torch.from_numpy(blur_).type(cuda_tensor)[None, None, :, :]\n",
    "    img_fake_B = (img_fake_B - 0.5)*2.0\n",
    "    \n",
    "    fake_C_ST_GAN = G2_trained(torch.cat((input_img, img_fake_B), 1))\n",
    "    RES = test_model.get_prediction(input_img, img_fake_B)\n",
    "    \n",
    "    epoch_index += 1\n",
    "    for i in range(len(list_A)):\n",
    "        img_real_A = list_A[i].permute(1, 2, 0)\n",
    "        img_real_C = list_C[i].permute(1, 2, 0)\n",
    "        img_fake_C = fake_C_ST_GAN[i].data.permute(1, 2, 0)\n",
    "        img_fake_C_SID = RES['final'][i].data.permute(1, 2, 0)\n",
    "        \n",
    "        my_psnr += calculate_psnr(img_real_C, img_real_A)\n",
    "        my_ssim += calculate_ssim(img_real_C, img_real_A)\n",
    "\n",
    "        my_psnr_A += calculate_psnr(img_real_C, img_fake_C)\n",
    "        my_ssim_A += calculate_ssim(img_real_C, img_fake_C)\n",
    "        \n",
    "        my_psnr_B += calculate_psnr(img_real_C, img_fake_C_SID)\n",
    "        my_ssim_B += calculate_ssim(img_real_C, img_fake_C_SID)\n",
    "\n",
    "        #Scale to 255\n",
    "        img_real_A = ((img_real_A + 1.0)*255.0/2.0).cpu().numpy().astype(np.uint8)\n",
    "        img_real_C = ((img_real_C + 1.0)*255.0/2.0).cpu().numpy().astype(np.uint8) \n",
    "        img_fake_C = ((img_fake_C + 1.0)*255.0/2.0).cpu().numpy().astype(np.uint8) \n",
    "        img_fake_C_SID = ((img_fake_C_SID + 1.0)*255.0/2.0).cpu().numpy().astype(np.uint8) \n",
    "\n",
    "        \n",
    "        data_name = os.getcwd() + f\"\\\\result_set\\\\original\\\\{list_imname[i]}\"\n",
    "        Image.fromarray(img_real_A).convert('RGB').resize((224, 224)).save(data_name)\n",
    "        \n",
    "        data_name = os.getcwd() + f\"\\\\result_set\\\\stgan\\\\{list_imname[i]}\"              \n",
    "        Image.fromarray(img_fake_C).convert('RGB').resize((224, 224)).save(data_name)\n",
    "        \n",
    "        data_name = os.getcwd() + f\"\\\\result_set\\\\sid\\\\{list_imname[i]}\"              \n",
    "        Image.fromarray(img_fake_C_SID).convert('RGB').resize((224, 224)).save(data_name)\n",
    "        \n",
    "        data_name = os.getcwd() + f\"\\\\result_set\\\\groudtruth\\\\{list_imname[i]}\"              \n",
    "        Image.fromarray(img_real_C).convert('RGB').resize((224, 224)).save(data_name)\n",
    "        \n",
    "#     if epoch_index == 20:\n",
    "#         break\n",
    "    \n",
    "length = len(dataset)\n",
    "print(\"Amount of data: \", length)\n",
    "print(\"PSNR 0: \", my_psnr/length, \"SSIM 0: \", my_ssim/length)\n",
    "print(\"PSNR A: \", my_psnr_A/length, \"SSIM A: \", my_ssim_A/length)\n",
    "print(\"PSNR B: \", my_psnr_B/length, \"SSIM B: \", my_ssim_B/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecfb727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
